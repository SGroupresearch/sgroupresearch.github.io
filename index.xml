<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>SGroup Research</title>
    <link>https://sgroupresearch.github.io/</link>
    <description>Recent content on SGroup Research</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sat, 19 Mar 2022 15:30:00 +0901</lastBuildDate>
    
	<atom:link href="https://sgroupresearch.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>A   Backbone-Listener Relative  Localization Scheme   for Distributed Multi-agent Systems</title>
      <link>https://sgroupresearch.github.io/gc2022/</link>
      <pubDate>Sat, 19 Mar 2022 15:30:00 +0901</pubDate>
      
      <guid>https://sgroupresearch.github.io/gc2022/</guid>
      <description>Authors  Xiaoxiang Li (EE, Tsinghua University) lxx17@mails.tsinghua.edu.cn Yunlong Wang (EE, Tsinghua University) ylwang_ee@tsinghua.edu.cn Yan Liu (China Satellite Network Innovation Co., Ltd.) liu-y15g@tsinghua.org.cn Yuan Shen (EE, Tsinghua University) shenyuan_ee@tsinghua.edu.cn  Abstract Reliable and accurate localization awareness is of great importance for the distributed multi-agent system (D-MAS). Instead of global information, measurements only between neighbors pose many challenges for distributed systems, which leads to the development and application of relative localization. In this paper, we put forward a backbone-listener localization scheme for the D-MAS.</description>
    </item>
    
    <item>
      <title>CORELS:  A Cooperative Relative Localization System for Multi-agent Networks</title>
      <link>https://sgroupresearch.github.io/corels/</link>
      <pubDate>Sat, 19 Mar 2022 15:30:00 +0901</pubDate>
      
      <guid>https://sgroupresearch.github.io/corels/</guid>
      <description>Authors  Xiaoxiang Li (EE, Tsinghua University) lxx17@mails.tsinghua.edu.cn Kai Ma (EE, Tsinghua University) mk19@mails.tsinghua.edu.cn Lingwei Xu (EE, Tsinghua University) xlw18@mails.tsinghua.edu.cn Yunlong Wang (EE, Tsinghua University) &amp;lt; ylwang_ee@tsinghua.edu.cn&amp;gt; Jian Wang (EE, Tsinghua University) jian-wang@tsinghua.edu.cn Yuan Shen (EE, Tsinghua University) shenyuan_ee@tsinghua.edu.cn  Abstract Reliable and accurate spatio-temporal information is of great importance for multi-agent networks. Cooperative relative localization technologies provide a promising paradigm for such information, especially in GNSS-denied or infrastructure-free scenarios without absolute position reference.</description>
    </item>
    
    <item>
      <title>A Deep Reinforcement Learning Based Approach for Autonomous Overtaking</title>
      <link>https://sgroupresearch.github.io/drlovertaking/</link>
      <pubDate>Thu, 19 Aug 2021 15:30:00 +0901</pubDate>
      
      <guid>https://sgroupresearch.github.io/drlovertaking/</guid>
      <description>ArXiv: arXiv:xxxx.xxxxx
Authors  Xiaoxiang Li (EE, Tsinghua University) lxx17@mails.tsinghua.edu.cn Xinyou Qiu (EE, Tsinghua University) qxy18@mails.tsinghua.edu.cn Jian Wang (EE, Tsinghua University) jian-wang@tsinghua.edu.cn Yuan Shen (EE, Tsinghua University) shenyuan_ee@tsinghua.edu.cn  * Equal contribution.
Abstract â€‹	In this paper, we propose a deep reinforcement learning scheme, based on deep deterministic policy gradient, to train the overtaking actions for autonomous vehicles. In contrast to conventional autonomous driving systems which require for expensive LiDAR or visual cameras, our method uses low cost sensors like ultra-wide-band antenna arrays and inertial measurement units to obtain easily available measurements such as distance, angle, and speed information.</description>
    </item>
    
    <item>
      <title>Distributed Relative Formation and Obstacle Avoidance with Multi-agent Reinforcement Learning</title>
      <link>https://sgroupresearch.github.io/relativeformation/</link>
      <pubDate>Thu, 19 Aug 2021 15:30:00 +0901</pubDate>
      
      <guid>https://sgroupresearch.github.io/relativeformation/</guid>
      <description>Authors  Yuzi Yan (EE, Tsinghua University) yan-yz17@tsinghua.org.cn Xiaoxiang Li (EE, Tsinghua University) lxx17@mails.tsinghua.edu.cn Xinyou Qiu (EE, Tsinghua University) qxy18@mails.tsinghua.edu.cn Jiantao Qiu (EE, Tsinghua University) qjt15@mails.tsinghua.edu.cn Jian Wang (EE, Tsinghua University) jian-wang@tsinghua.edu.cn Yu Wang (EE, Tsinghua University) yu-wang@tsinghua.edu.cn Yuan Shen (EE, Tsinghua University) shenyuan_ee@tsinghua.edu.cn  Abstract Multi-agent formation as well as obstacle avoidance is one of the most actively studied topics in the field of multi-agent systems. Although some classic controllers like model predictive control (MPC) and fuzzy control achieve a certain measure of success, most of them require precise global information which is not accessible in harsh environments.</description>
    </item>
    
    <item>
      <title>AdaSpeech 3: Adaptive Text to Speech for Spontaneous Style</title>
      <link>https://sgroupresearch.github.io/adaspeech3/</link>
      <pubDate>Wed, 02 Jun 2021 11:35:23 +0800</pubDate>
      
      <guid>https://sgroupresearch.github.io/adaspeech3/</guid>
      <description>ArXiv: arXiv:2107.02530
Accepted by INTERSPEECH 2021
Author  Yuzi Yan (EE, Tsinghua University) yan-yz17@mails.tsinghua.edu.cn Xu Tan (Microsoft Research Asia) xuta@microsoft.com Bohan Li (Microsoft Azure Speech) bohan.li@microsoft.com Guangyan Zhang (EE, The Chinese University of Hong Kong) gyzhang@link.cuhk.edu.hk Tao Qin (Microsoft Research Asia) taoqin@microsoft.com Sheng Zhao (Microsoft Azure Speech) sheng.zhao@microsoft.com Yuan Shen (EE, Tsinghua University) shenyuan_ee@tsinghua.edu.cn Wei-Qiang Zhang (EE, Tsinghua University) wqzhang@tsinghua.edu.cn Tie-Yan Liu (Microsoft Research Asia) tie-yan.liu@microsoft.com  Audio Samples All of the audio samples use MelGAN as vocoder.</description>
    </item>
    
    <item>
      <title>AdaSpeech 2: Adaptive Text to Speech with Untranscribed Data</title>
      <link>https://sgroupresearch.github.io/adaspeech2/</link>
      <pubDate>Fri, 05 Mar 2021 11:35:23 +0800</pubDate>
      
      <guid>https://sgroupresearch.github.io/adaspeech2/</guid>
      <description>ArXiv: arXiv:2104.09715
Accepted by ICASSP 2021
Author  Yuzi Yan (EE, Tsinghua University) yan-yz17@mails.tsinghua.edu.cn Xu Tan (Microsoft Research Asia) xuta@microsoft.com Bohan Li (Microsoft Azure Speech) bohan.li@microsoft.com Tao Qin (Microsoft Research Asia) taoqin@microsoft.com Sheng Zhao (Microsoft Azure Speech) szhao@microsoft.com Yuan Shen (EE, Tsinghua University) shenyuan_ee@tsinghua.edu.cn Tie-Yan Liu (Microsoft Research Asia) tie-yan.liu@microsoft.com  Audio Samples All of the audio samples use MelGAN as vocoder.
Audio Quality When a man looks for something beyond his reach, his friends say he is looking for the pot of gold at the end of the rainbow.</description>
    </item>
    
  </channel>
</rss>